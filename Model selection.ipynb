{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор модели для предсказания модели. \n",
    "\n",
    "Грузим данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data_5.pkl\", 'rb') as f:\n",
    "    X_pairs, y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105023, 105023)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_pairs), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-й и 8-й элементы - это текстовые данные. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('просторный таунхаус  с отдельно стоящим гаражом на 2 машины площадь около 30  квм в посёлке ангеловорезиденц на пятницком шоссе основа дома  монолитный каркас с отделкой кирпичом в доме 3 этажа включая мансарду и подвал который по площади как первый этаж всего на этих трёх этажах 8 комнат на первом этаже прихожая выход на террасу кухня полностью оборудованная гостиная и зал с камином кабинет гостевой санузелна втором этаже родительская спальня с гардеробной комнатой и санузлом с душевой кабиной и ванной 2 спальни со смежным санузлом с душевой кабиной в каждой спальне встроенные шкафы для вещей кабинетспальня со встроенным шкафом санузел с душевой кабинойна третьем этаже спальня с кладовкой и санузлом с душевой кабиной комната свободного назначения с санузломна цокольном этажев подвале прачечная со стиральной и сушильной машинами 7 комнат свободного назначения сейчас используются для хранения личных вещей бойлернаятехническое помещение с отдельной дверью для доступа техническихгазовых служб санузелдом оборудован бойлерным оборудованием производства компании ferroli в дом заведена холодная вода и газ отопление за счёта газа оплата по счётчикам воды газа и электроэнергии дом полностью готов к проживанию',\n",
       " 'id 2218 предлагаем на продажу самый большой и просторный таунхаус в кп ангелово резиденс  общей площадью 600м2 расположенный всего в 4 км от мкад по пятницкому шоссе планировочное решение 1 этаж гостиная и зал с камином оборудованная кухня столовая родительская спальня с гардеробной комнатой санузлом с душевой кабиной и ванной 2 этаж  4 спальни со встроенными шкафами смежным санузлом и душевой кабиной кабинет 3 этаж  4 гостевых санузла несколько комнат свободного назначения цоколь техническое и хозяйственное помещения все центральные коммуникации имеется гараж на 2 машины',\n",
       " 'россия московская область городской округ красногорск село ангелово жилой комплекс ангеловорезиденц',\n",
       " 'московская область одинцовский район ангелово')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X_pairs[0]\n",
    "\n",
    "x[0][0], x[1][0], x[0][8],x[1][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pairs, X_test_pairs, y_train, y_test = train_test_split(X_pairs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем текстовый корпус из всех текстовых данных тренировочного сета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28435\n"
     ]
    }
   ],
   "source": [
    "text_data = []\n",
    "\n",
    "for x in X_train_pairs:\n",
    "    text_data.append(x[0][0])\n",
    "    text_data.append(x[1][0])\n",
    "    text_data.append(x[0][8])\n",
    "    text_data.append(x[1][8])\n",
    "    \n",
    "text_data = list(set(text_data))\n",
    "print(len(text_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим фаст текст на нашем корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasttext_classifier import FastTextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train unsupervised model.\n",
      "Model trained with user parameters:\n",
      "{'epoch': 10, 'dim': 100}.\n"
     ]
    }
   ],
   "source": [
    "ft = FastTextClassifier(epoch=10, dim=100)\n",
    "ft.fit(text_data)\n",
    "ft.save(\"ft_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = FastTextClassifier(epoch=10, dim=100)\n",
    "ft.load(\"ft_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация данных.\n",
    "\n",
    "Для текстовых данных мы считаем косинусное расстояние между энбеддингами предложений пары.\n",
    "\n",
    "Для числовых данных считаем абсолютную разность.\n",
    "\n",
    "Для всех других просто смотрим их равенство."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные ледат в таком порядке:\n",
    "\n",
    "1. description\n",
    "2. roomscount\n",
    "3. floornumber\n",
    "4. category\n",
    "5. totalarea\n",
    "6. flattype\n",
    "7. userid\n",
    "8. publisheduseri\n",
    "9. userInput\n",
    "10. floorsCount\n",
    "11. totalArea\n",
    "12. price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_data(X_pairs, ft):\n",
    "\n",
    "    X = []\n",
    "\n",
    "    for ix, x in enumerate(X_pairs):\n",
    "        name_cos = cos_sim(ft.transform(x[0][0]), ft.transform(x[1][0]))\n",
    "        addr_cos = cos_sim(ft.transform(x[0][8]), ft.transform(x[1][8]))\n",
    "        same_roomscount  = int(x[0][1] == x[1][1])\n",
    "        same_floornumber = int(x[0][2] == x[1][2])\n",
    "        same_category    = int(x[0][3] == x[1][3])\n",
    "        same_totalarea   = int(x[0][4] == x[1][4] )\n",
    "        same_flattype    = int(x[0][5] == x[1][5] )\n",
    "        same_userid      = int(x[0][6] == x[1][6] )\n",
    "        same_publisheduseri = int(x[0][7] == x[1][7])\n",
    "        diff_floorsCount    = np.abs(x[0][9] - x[1][9])\n",
    "        diff_totalArea      = np.abs(x[0][10] - x[1][10])\n",
    "        diff_price          = np.abs(x[0][11] - x[1][11])\n",
    "\n",
    "        X.append([name_cos, addr_cos, same_roomscount, same_floornumber, same_category, same_totalarea, same_flattype, \n",
    "    same_userid, same_publisheduseri, diff_floorsCount, diff_totalArea, diff_price])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(create_data(X_train_pairs, ft))\n",
    "X_test = np.array(create_data(X_test_pairs, ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.00978088e-01, 8.39517057e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.20000000e+01, 1.00000000e+02, 1.37000000e+06])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     23720\n",
      "           1       0.95      0.95      0.95      2536\n",
      "\n",
      "    accuracy                           0.99     26256\n",
      "   macro avg       0.97      0.97      0.97     26256\n",
      "weighted avg       0.99      0.99      0.99     26256\n",
      "\n",
      "[[23591   129]\n",
      " [  135  2401]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ss = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_s = ss.transform(X_train)\n",
    "X_test_s = ss.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_s, y_train)\n",
    "y_pred = clf.predict(X_test_s)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23720\n",
      "           1       0.98      0.97      0.97      2536\n",
      "\n",
      "    accuracy                           1.00     26256\n",
      "   macro avg       0.99      0.99      0.99     26256\n",
      "weighted avg       1.00      1.00      1.00     26256\n",
      "\n",
      "[[23657    63]\n",
      " [   64  2472]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем модель RF так как она показала отличные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
